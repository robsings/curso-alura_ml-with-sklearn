{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPjxOAyuFzmzBB94FLgUSc5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Lendo e manipulando dados da internet**"],"metadata":{"id":"rTqhBmlls6lJ"}},{"cell_type":"markdown","source":["## **Fundamentos/Teoria**\n","A ideia agora é trabalharmos em um novo projeto com dados diferentes. Assim, conseguimos passar por vários projetos, com muitas similaridades, mas que nos permitem praticar diversas fases e suas variações, algo essencial para entendermos melhor as fases.\n","\n","### **Conhecendo o arquivo `tracking.csv`**\n","Assim como antes, precisaremos carregar os dados, mas desta vez, em vez de digitar diversos dados, faremos como no mundo real e forneceremos os dados em algum tipo de arquivo já formatado.\n","\n","Nesse caso, usaremos um arquivo CSV chamado `tracking.csv`, disponibilizado no GitHub e composto por uma série de dados. Acessando a [versão crua do arquivo](https://gist.githubusercontent.com/guilhermesilveira/b9dd8e4b62b9e22ebcb9c8e89c271de4/raw/c69ec4b708fba03c445397b6a361db4345c83d7a/tracking.csv), em \"Raw\" no canto superior direito, identificamos várias colunas. São elas:\n","\n","```markdown\n","* inicial;\n","* palestras;\n","* contato;\n","* comprou;\n","* E patrocinio\n","```\n","\n","Esse conjunto de dados representa pessoas usuárias acessando o website. Nesse caso, temos um site onde vendemos ingressos para um evento de inteligência artificial. Gostaríamos que as pessoas comprassem o ingresso no site, então seria interessante analisar o comportamento das pessoas.\n","\n","Se determinada pessoa usuária entrou na página inicial, marcamos 1 nessa coluna. Seguimos a mesma lógica para: pessoas que entraram na página de palestras; pessoas que entraram na página de contato; pessoas que compraram; e pessoas que entraram na página de patrocínio.\n","\n","Portanto, temos 5 páginas no nosso site, e para cada pessoa usuária, temos um item correspondente no arquivo CSV, representado por uma linha indicando se ela acessou ou não a página.\n","\n","A primeira coluna, por exemplo, indica com 1 ou 0 se a pessoa acessou o site pela página inicial ou não, respectivamente. No entanto, nem sempre a pessoa entra na página inicial. Por exemplo: se enviarmos o link da página de contato para alguém, a pessoa não passa pela página inicial.\n","\n","Agora que temos todos os dados de interesse, podemos carregar esse arquivo.\n","\n","### **Importando a biblioteca Pandas**\n","\n","Em uma nova célula, usaremos uma *biblioteca* base de ciência de dados para carregar CSVs: o **Pandas**. Dito isso, vamos importar pandas como _pd_, forma tradicional de importação.\n","\n","`import pandas as pd`\n","\n","### **Carregando os dados**\n","Em seguida, adicionaremos a URL que vamos carregar, então definimos uri igual ao endereço do arquivo _tracking.csv_ entre aspas duplas. Dessa forma, teremos o conjunto de dados carregado.\n","\n","```python\n","import pandas as pd\n","\n","uri = \"https://gist.githubusercontent.com/guilhermesilveira/b9dd8e4b62b9e22ebcb9c8e89c271de4/raw/c69ec4b708fba03c445397b6a361db4345c83d7a/tracking.csv\"\n","```\n","\n","### **Lendo os dados**\n","O próximo passo será ler os dados carregados. Para isso, atribuiremos à variável dados o método `pd.read_csv(uri)`. Por fim, podemos usar `dados.head()` para visualizar as cinco primeiras linhas.\n","\n","```python\n","import pandas as pd\n","\n","uri = \"https://gist.githubusercontent.com/guilhermesilveira/b9dd8e4b62b9e22ebcb9c8e89c271de4/raw/c69ec4b708fba03c445397b6a361db4345c83d7a/tracking.csv\"\n","dados = pd.read_csv(uri)\n","dados.head()\n","```\n","\n","Ao executar a célula, o Colab irá carregar da internet o arquivo enviado no código, aplicar essa tabela de dados na memória através da biblioteca Pandas, e exibir as cinco primeiras linhas de dados.\n","\n","### **Analisando o resultado**\n","\n","As colunas, conforme visto anteriormente, são **inicial, palestra, contatos, comprou e patrocinio**, e no resultado das cinco primeiras linhas da tabela, temos inicial definido como 1, palestras como 1, contato como 0, comprou como 0, e patrocinio também como 0.\n","\n","Concluímos que as 5 primeiras pessoas usuárias tiveram, praticamente, o mesmo comportamento.\n","\n","**Nosso objetivo é treinar para tentar adivinhar se a pessoa vai ou não comprar, pois, se a pessoa não for comprar, gostaríamos que aparecesse no canto da página uma mensagem, como: \"Olá! Gostaria de conversar conosco para entender se faz sentido você comprar o ingresso para o nosso evento?\".**\n","\n","A ideia é mostrar esse anúncio somente se acharmos que a pessoa não vai comprar. Se ela vai comprar e exibimos um anúncio desse tipo na tela, podemos, inclusive, atrapalhar a navegação da pessoa. Portanto, é importante estimar se a pessoa vai comprar ou não.\n","\n","### **Fazendo uma estimativa da coluna comprou**\n","Nesse caso, a coluna que precisamos estimar é a _comprou_, que é a coluna _y (dados[\"comprou\"])_.\n","\n","```python\n","y = dados[\"comprou\"]\n","y.head()\n","```\n","\n","### **Fazendo uma estimativa das demais colunas**\n","Já o nosso _x_ é representado por `dados[[\"inicial\", \"palestras\", \"contato\", \"patrocinio\"]]`, ou seja, selecionamos todas as colunas, exceto a _comprou_, verificada anteriormente.\n","\n","```python\n","x = dados[[\"inicial\", \"palestras\",\t\"contato\",\t\"patrocinio\"]]\n","x.head()\n","```\n","Assim, temos _x_ e _y_. A partir deles, conseguimos trabalhar como desejado.\n","\n","### **Exibindo o formato da tabela**\n","Algo interessante é que podemos usar uma nova célula para conferir o _número de linhas_ existentes na tabela. Para isso, basta usar o comando `dados.shape`, responsável por retornar o formato.\n","Nesse caso, temos 99 linhas e 5 colunas.\n","\n","### **Treinando o modelo**\n","Nosso próximo passo será treinar o modelo, assim como antes. Em uma nova célula, iniciaremos com o comando `from sklearn.svm import LinearSVC` para importar a classe **_LinearSVC_**.\n","\n","Em seguida, para criar o modelo efetivamente, declaramos modelo igual a **_LinearSVC()_**. Abaixo, vamos chamar `modelo.fit()` recebendo _x_ e _y_ entre parênteses.\n","\n","```python\n","from sklearn.svm import LinearSVC\n","\n","modelo = LinearSVC()\n","modelo.fit(x, y)\n","```\n","\n","Logo em seguida, precisamos calcular as _previsões_. No entanto, no exemplo acima, pedimos para o modelo treinar todas as pessoas usuárias adicionadas ao carregar os dados.\n","\n","Depois, se criamos um modelo matemático que faz sentido em relação à previsão de quem vai ou não comprar, apresentamos e testamos com as mesmas pessoas.\n","\n","Parece haver algo errado nesse processo, pois quando fazemos o treino e o teste, não podemos testar naquilo que treinamos. É necessário testar em algo que não conhecemos.\n","\n","**Para verificar se o modelo realmente aprendeu, não podemos treinar e testar as mesmas coisas.**\n","\n","No pior dos cenários, o modelo será tão bom, no sentido de ter uma grande memória, que ele haverá decorado tudo. Se o modelo tem uma ótima memória e é grande o suficiente, basta ele memorizar cada um dos casos. Dessa forma, ele fica perfeito, o que chamamos de **overfit**.\n","\n","Nesse caso, o modelo não nos servirá tanto, pois quando usarmos um exemplo de fora, ele não terá aprendido o que é esse exemplo, uma vez que ele apenas decorou os dados carregados.\n","\n","Sendo assim, precisaremos separar quem é treino e quem é teste.\n","\n","Separando dados de treino e de teste\n","Para isso, criaremos uma nova célula de código após o retorno do comando `dados.shape`, e indicaremos que os primeiros elementos serão usados para treino.\n","\n","Assim, podemos declarar _treino_x_ igual aos primeiros *75 elementos de x*, ou seja, `x[:75]`. Em seguida, faremos o mesmo para _treino_y_, que será igual aos primeiros *75 elementos de y*.\n","\n","```python\n","treino_x = x[:75]\n","treino_y = y[:75]\n","```\n","Logo, para treinar, usaremos os primeiros 3 quartos de elementos *(considerando o total de 99 itens)*, aproximadamente, ou seja, **75% dos elementos**. Portanto, no `método fit()` aplicado na célula que criamos anteriormente, adicionaremos as variáveis *treino_x* e *treino_y*.\n","\n","```python\n","from sklearn.svm import LinearSVC\n","\n","modelo = LinearSVC()\n","modelo.fit(treino_x, treino_y)\n","```\n","Dessa forma, os últimos 24 elementos, correspondentes ao último quarto, não são conhecidos pelo nosso modelo, isto é, ele nunca viu esses elementos e não sabe quem são as pessoas usuárias.\n","\n","Portanto, o modelo precisará extrapolar os seus aprendizados. Dito isso, podemos separar os testes: o *teste_x* será igual a `x[75:]`; enquanto o *teste_y* será igual a `y[75:]`.\n","\n","```python\n","treino_x = x[:75]\n","treino_y = y[:75]\n","\n","teste_x = x[75:]\n","teste_y = y[75:]\n","```\n","Para finalizar, vamos usar o método `print()` indicando que treinaremos com um número específico de elementos. Entre os parênteses do primeiro `print()`, vamos adicionar `f\"Treinaremos com {len(treino_x)} elementos\"`. Podemos duplicar essa linha abaixo e substituir por *teste_x*.\n","\n","```python\n","treino_x = x[:75]\n","treino_y = y[:75]\n","\n","teste_x = x[75:]\n","teste_y = y[75:]\n","\n","print(f\"Treinaremos com {len(treino_x)} elementos\")\n","print(f\"Testaremos com {len(teste_x)} elementos\")\n","```\n","### **Finalizando o treinamento do modelo**\n","Agora, de volta à célula do treinamento do modelo, precisamos calcular a previsão efetivamente. Para isso, vamos declarar a variável previsoes igual a `modelo.predict(teste_x)`.\n","```python\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import accuracy_score\n","\n","modelo = LinearSVC()\n","modelo.fit(treino_x, treino_y)\n","previsoes = modelo.predict(teste_x)\n","```\n","Agora que temos as previsões, basta chamar a acurácia. Para isso, vamos definir acuracia igual a `accuracy_score()`. Automaticamente, o Colab sugere o seguinte preenchimento do código:\n","```python\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import accuracy_score\n","\n","modelo = LinearSVC()\n","modelo.fit(treino_x, treino_y)\n","previsoes = modelo.predict(teste_x)\n","\n","acuracia = accuracy_score(teste_y, previsoes) * 100\n","print(f\"A acurácia foi de {acuracia:.2f}%\")\n","```\n","Realizamos manualmente a importação de `accuracy_score` no início do código, com o comando `from sklearn.metrics import accuracy_score`.\n","\n","Usamos a função `accuracy_score()`, passando para ela tanto o *teste_y* quanto as previsoes. Ao final, transformamos em porcentagem e imprimimos o resultado.\n","\n","Como retorno, temos a informação que a acurácia foi de *95.83%*.\n","\n","A sua acurácia pode ser um pouco diferente da que recebemos como retorno. Posteriormente no curso, abordaremos questões de valores e aleatoriedade para entender isso melhor.\n","\n","### **Conclusão**\n","Note que realizamos o mesmo processo de antes, **_ou seja, separamos os dados em treino e teste_**, mas agora entendemos o porquê da necessidade dessa separação: **_o modelo não pode memorizar os dados_**. Por outro lado, se ele entender o que os dados significam, tudo ocorre conforme esperado.\n","\n","Dito isso, testamos se o modelo entendeu de forma mínima, isto é, suficiente, o que significa uma pessoa usuária querer ou não comprar. Com uma acurácia de *95%*, temos um resultado positivo.\n"],"metadata":{"id":"S90wEsrds9D5"}},{"cell_type":"markdown","source":["# **Tutoriais, exemplos e exercícios - Aula: Lendo e manipulando dados da internet**\n"],"metadata":{"id":"3WwpXqkYI_fG"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import accuracy_score\n","\n","modelo = LinearSVC()\n","\n","# Obtenção de dados\n","uri = \"https://gist.githubusercontent.com/guilhermesilveira/b9dd8e4b62b9e22ebcb9c8e89c271de4/raw/c69ec4b708fba03c445397b6a361db4345c83d7a/tracking.csv\"\n","\n","dados = pd.read_csv(uri)\n","\"\"\"dados.head() # Exibi as 5 primeiras linhas\"\"\"\n","\n","# Separação de dados\n","y = dados[\"comprou\"]\n","x = dados[[\"inicial\", \"palestras\", \"contato\", \"patrocinio\"]]\n","\n","\"\"\"x.head() # y.head()\"\"\"\n","\n","\"\"\"dados.shape # Aqui podemos verificar o numero de linhas e colunas existentes na tabela\"\"\"\n","treino_x = x[:75]\n","treino_y = y[:75]\n","teste_x = x[75:]\n","teste_y = y[75:]\n","\n","# Treino\n","modelo.fit(treino_x, treino_y)\n","print(f\"Treinaremos com {len(treino_x)} elementos\\n\"\n","f\"e testaremos com {len(teste_x)} elementos\")\n","\n","previsoes = modelo.predict(teste_x)\n","\n","acuracia = accuracy_score(teste_y, previsoes) * 100\n","print(f\"A acurácia foi de {acuracia: .2f}%\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ab6MaMRiJNdN","executionInfo":{"status":"ok","timestamp":1763490416602,"user_tz":180,"elapsed":353,"user":{"displayName":"Robert Saint's","userId":"15691013392445574826"}},"outputId":"82ff0416-db64-4464-ef35-12d2a63d01d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Treinaremos com 75 elementos\n","e testaremos com 24 elementos\n","A acurácia foi de  95.83%\n"]}]},{"cell_type":"markdown","source":["# **Termos e conceitos relacionados**\n"],"metadata":{"id":"zUoHddP_dYSe"}},{"cell_type":"markdown","source":["## **Overfitting**\n","---\n","No universo da ciência de dados e do aprendizado de máquina, o termo “overfitting” frequentemente surge em discussões técnicas e análises de modelos. O overfitting, ou sobreajuste, é um fenômeno onde um modelo estatístico se ajusta tão bem aos dados de treinamento que perde a capacidade de generalizar para novos dados.\n","\n","*Para entender o overfitting, é essencial primeiro compreender o que significa ajustar um modelo aos dados. Quando treinamos um modelo de machine learning, nosso objetivo é encontrar padrões nos dados de treinamento que possam ser aplicados a novos dados não vistos.* Contudo, quando o modelo se ajusta demasiadamente aos dados de treinamento, ele começa a capturar o “ruído” ou as variações aleatórias nos dados, em vez dos padrões subjacentes.\n","\n","Imagine que você está tentando prever a altura de uma pessoa com base em sua idade. Se seu modelo é muito complexo, ele pode acabar capturando flutuações aleatórias nos dados de treinamento que não são representativas da relação geral entre idade e altura. Como resultado, embora o modelo apresente uma excelente performance nos dados de treinamento, seu desempenho nos dados de teste (ou em dados novos) será pobre.\n","\n","Uma das maneiras mais diretas de identificar o overfitting é comparar o desempenho do modelo nos dados de treinamento com o desempenho em um conjunto de validação. Se o modelo tiver um desempenho significativamente melhor nos dados de treinamento do que no conjunto de validação, isso é um forte indicativo de overfitting.\n","\n","\n"],"metadata":{"id":"izx7Hpf7dkEV"}},{"cell_type":"markdown","source":["# **Tutoriais, exemplos e exercícios - Aula: Estratificando splits**"],"metadata":{"id":"zcXUoqOrhBYN"}},{"cell_type":"markdown","source":["Inicialmente, em uma nova célula, precisamos separar entre treino e teste, então teremos `train_test_split()` recebendo _x_ e _y_ entre parênteses.\n","\n","Nessa etapa, também precisaremos importar o `train_test_split` de `sklearn.model_selection`.\n","\n","```python\n","from sklearn.model_selection import train_test_split\n","\n","train_test_split(x, y)\n","```\n","Ao executar a célula, recebemos como retorno uma série de informações.\n","\n","Observe que é retornada uma primeira tabela grande, com 74 linhas e 4 colunas; depois recebemos outra tabela com 25 linhas e 4 colunas; e assim por diante. Na prática, ele separou os dados de treino e teste em quatro partes, conforme esperado. As quatro partes que esperávamos eram:\n","\n","```markdown\n","* treino_x;\n","* teste_x;\n","* treino_y;\n","* E teste_y.\n","```\n","\n","Se aplicarmos essas variáveis na célula atual e trouxermos os dois `print()` executados anteriormente, receberemos as mensagens **\"Treinaremos com 74 elementos\"** e **\"Testaremos com 25 elementos\"**.\n","\n","```python\n","from sklearn.model_selection import train_test_split\n","\n","treino_x, teste_x, treino_y, teste_y = train_test_split(x, y)\n","\n","print(f\"Treinaremos com {len(treino_x)} elementos\")\n","print(f\"Testaremos com {len(teste_x)} elementos\")\n","```\n","\n","## **Testando o modelo**\n","\n","Agora, podemos copiar o código da última célula executada, onde fizemos o treinamento do modelo, e colar na célula na qual estamos trabalhando, apenas movendo os `import` para o topo do código.\n","\n","```python\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import accuracy_score\n","\n","treino_x, teste_x, treino_y, teste_y = train_test_split(x, y)\n","\n","print(f\"Treinaremos com {len(treino_x)} elementos\")\n","print(f\"Testaremos com {len(teste_x)} elementos\")\n","\n","modelo = LinearSVC()\n","modelo.fit(treino_x, treino_y)\n","previsoes = modelo.predict(teste_x)\n","\n","acuracia = accuracy_score(teste_y, previsoes) * 100\n","print(f\"A acurácia foi de {acuracia:.2f}%\")\n","```\n","\n","```markdown\n","Treinaremos com 74 elementos\n","Testaremos com 25 elementos\n","A acurácia foi de 96.00%\n","```\n","Nesse caso, 74 elementos serão treinados, 25 serão testados, e a acurácia foi de 96%.\n","\n","Note que obtivemos uma acurácia um pouco maior, embora o treinamento tenha acontecido com 1 elemento a menos. Ao executar novamente a célula, recebemos uma acurácia diferente, de 100%. Repetindo o processo, recebemos 96% mais uma vez, depois voltamos para 100%, e assim sucessivamente.\n","\n","### Por que cada vez é retornado um valor diferente?\n","Pode ser que haja algum tipo de aleatoriedade. Na prática, temos 99 itens. Quais elementos devem ser usados para treino? Os 74 primeiros? Os 74 últimos? Os 74 do meio? Qual regra devemos aplicar?\n","\n","## **Entendendo a aleatoriedade**\n","Anteriormente, usamos uma primeira regra selecionando os primeiros 74 elementos. Agora, imagine se tivéssemos 99 animais, por exemplo, sendo 75 cachorros e 24 porcos, e rodássemos o primeiro algoritmo:\n","\n","```python\n","treino_x = x[:75]\n","treino_y = y[:75]\n","\n","teste_x = x[75:]\n","teste_y = y[75:]\n","\n","print(f\"Treinaremos com {len(treino_x)} elementos\")\n","print(f\"Testaremos com {len(teste_x)} elementos\")\n","```\n","Nesse caso, colocaríamos todos os cachorros no treino e todos os porcos no teste, o que não funcionaria. Sendo assim, por padrão, os algoritmos têm aleatoriedade para evitar tais situações.\n","\n","Com a documentação do **Scikit-learn** aberta, vamos acessar a página da função `train_test_split()`.\n","\n","Nessa página, encontramos um parâmetro chamado `random_state`, responsável por definir um valor semente que deve ser usado para aleatorizar os dados antes de fazer a seleção.\n","\n","## **Fixando a aleatoriedade**\n","Como queremos que a nossa pesquisa seja replicável, o objetivo é fixar a aleatoriedade. Deve ser obrigatoriamente aleatório, pois, caso contrário, será pré-definido. No entanto, temos a condição de que precisa ser _um aleatório igual em todos os casos_.\n","\n","Portanto, na função `train_test_split()`, passaremos o parâmetro `random_state` igual a **_SEED_**. Chamamos esse número de semente _(em inglês, seed)_. Feito isso, definiremos acima o **_SEED_** igual a um número qualquer desejado. No nosso caso, colocaremos _4364_ aleatoriamente, por exemplo.\n","\n","```python\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import accuracy_score\n","\n","SEED = 4364\n","\n","treino_x, teste_x, treino_y, teste_y = train_test_split(x, y, random_state = SEED)\n","\n","print(f\"Treinaremos com {len(treino_x)} elementos\")\n","print(f\"Testaremos com {len(teste_x)} elementos\")\n","\n","modelo = LinearSVC()\n","modelo.fit(treino_x, treino_y)\n","previsoes = modelo.predict(teste_x)\n","\n","acuracia = accuracy_score(teste_y, previsoes) * 100\n","print(f\"A acurácia foi de {acuracia:.2f}%\")\n","```\n","\n","Agora, ao executar a célula, teremos o resultado da acurácia como 96% em todas as ocorrências, ou seja, se executarmos a mesma célula outra vezes, continuaremos recebendo o valor de 96% para acurácia, pois a semente do gerador de números aleatórios será sempre 4364.\n","\n","Testando outros números, poderíamos receber resultados diferentes, mas sempre iguais para a mesma execução.\n","\n","## **Utilizando a função `value_counts()`**\n","alamos anteriormente que poderia acontecer de todos os elementos caírem em um grupo específico (por exemplo: todos os porcos em teste e todos os cachorros em treino), algo que não queremos.\n","\n","Para verificar se isso aconteceu ou não, podemos começar com *treino_y* em uma nova célula. Nesse caso, usaremos a função `value_counts()` para conferir como ele separa os zeros e uns.\n","\n","`treino_y.value_counts()`\n","\n","A função `value_counts()` diz que temos 49 zeros e 25 uns nos dados de *treino_y*. Na sequência, podemos fazer a mesma verificação com a variável *teste_y*.\n","\n","`teste_y.value_counts()`\n","\n","Agora, temos 17 zeros e 8 uns, ou seja, basicamente, o dobro de zeros em relação aos uns. No resultado de *treino_y*, também temos praticamente o dobro, então, neste caso, tivemos sorte.\n","\n","No entanto, se tivéssemos colocado outro número em **_SEED_**, poderíamos ter dado azar e recebido uma divisão desproporcional em treino e teste. Podemos ter tanto azar quanto sorte nos resultados.\n","\n","Por exemplo: testando um **_SEED_** igual a 20, temos resultados um pouco diferentes.\n","\n","```python\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import accuracy_score\n","\n","SEED = 20\n","\n","treino_x, teste_x, treino_y, teste_y = train_test_split(x, y, random_state = SEED)\n","\n","print(f\"Treinaremos com {len(treino_x)} elementos\")\n","print(f\"Testaremos com {len(teste_x)} elementos\")\n","\n","modelo = LinearSVC()\n","modelo.fit(treino_x, treino_y)\n","previsoes = modelo.predict(teste_x)\n","\n","acuracia = accuracy_score(teste_y, previsoes) * 100\n","print(f\"A acurácia foi de {acuracia:.2f}%\")\n","```\n","\n","```markdown\n","Treinaremos com 74 elementos\n","Testaremos com 25 elementos\n","A acurácia foi de 96.00%\n","```\n","`treino_y.value_counts()`\n","`teste_y.value_counts()`\n","\n","Nesse caso, as proporções ficaram erradas. Assim, entendemos que casos ruins podem acontecer. Pode ser que a distribuição das classes esteja desbalanceada no treino e no teste, o que não queremos.\n","\n","## **Utilizando o parâmetro `stratify`**\n","\n","Para evitar uma distribuição desbalanceada, vamos pedir proporcionalidade aplicando o parâmetro **_stratify_** na função `train_test_split()`. Nesse caso, queremos estratificar a variável _y_.\n","\n","```python\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import accuracy_score\n","\n","SEED = 20\n","\n","treino_x, teste_x, treino_y, teste_y = train_test_split(x, y, random_state = SEED, stratify=y)\n","\n","print(f\"Treinaremos com {len(treino_x)} elementos\")\n","print(f\"Testaremos com {len(teste_x)} elementos\")\n","\n","modelo = LinearSVC()\n","modelo.fit(treino_x, treino_y)\n","previsoes = modelo.predict(teste_x)\n","\n","acuracia = accuracy_score(teste_y, previsoes) * 100\n","print(f\"A acurácia foi de {acuracia:.2f}%\")\n","```\n","essa forma, teremos um resultado proporcional. Executando novamente a célula com o valor de **_SEED_** igual a 20, que gerada um resultado ruim antes, agora temos uma boa proporção.\n","\n","`treino_y.value_counts()`\n","`teste_y.value_counts()`\n","\n","Como não sabemos se vamos cair em um caso ruim, estratificamos as variáveis, pois queremos a mesma proporção de classes em ambas as fases, tanto de treino quanto de teste.\n","\n","Com isso, aprendemos a refinar a fase de treino, de modo que os resultados dos testes sejam mais válidos."],"metadata":{"id":"NzwKqCm6iMk4"}},{"cell_type":"markdown","source":["# Nova seção"],"metadata":{"id":"1YYPOgVTSZR1"}}]}